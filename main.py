# -*- coding: utf-8 -*-
"""Bara Ananda Wima.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1YeZoLtQQnWBsm-2haSprEnzrb_60rvA7

Bara Ananda Wima

Bergabung sejak 17 Jan 2022
"""

import tensorflow as tf
print(tf.__version__)

!wget --no-check-certificate \
   https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \
   -O /tmp/rockpaperscissors.zip

# Commented out IPython magic to ensure Python compatibility.
import zipfile,os
import tensorflow as tf
from tensorflow.keras.constraints import max_norm
from tensorflow. keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt
import numpy as np
from google.colab import files
from keras.preprocessing import image
# %matplotlib inline

data_zip = "/tmp/rockpaperscissors.zip"
zip_ref = zipfile.ZipFile(data_zip, 'r')
zip_ref.extractall("/tmp")
zip_ref.close()

base_dir = "/tmp/rockpaperscissors"

DataGenerator = ImageDataGenerator(
              rescale = 1./255,
              validation_split = 0.4,
              shear_range = 0.3,
              zoom_range = 0.3,
              rotation_range = 20,
              horizontal_flip = True,
              vertical_flip = True,
              height_shift_range = 0.1,
              width_shift_range = 0.1,
              fill_mode = "nearest")

latih_datasets = DataGenerator.flow_from_directory(
                      base_dir,
                      subset = "training",
                      classes = ["paper", "rock", "scissors"],
                      target_size = (150,150),
                      batch_size = 32,
                      shuffle = True,
                      class_mode = "categorical")

validation_datasets = DataGenerator.flow_from_directory(
                            base_dir,
                            subset = "validation",
                            classes = ["paper", "rock", "scissors"],
                            target_size = (150, 150),
                            batch_size = 32,
                            shuffle = True,
                            class_mode = "categorical")

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation="relu"),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation="relu"),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(480, activation="relu"),
    tf.keras.layers.Dropout(0.3),
    tf.keras.layers.Dense(512, activation="relu"),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(3, activation='softmax')])

model.compile(loss = "categorical_crossentropy",
              optimizer = "RMSprop",
              metrics = ["accuracy"])

early_stops = EarlyStopping(
                  monitor = "val_loss",
                  mode = "min",
                  patience = 7,
                  verbose = 1)

model.fit(latih_datasets,
          epochs = 15,
          steps_per_epoch = 25,
          validation_data = validation_datasets,
          validation_steps = 5,
          verbose = 1)

uploaded_images = files.upload()

for keys in uploaded_images.keys():
  path = keys
  images = image.load_img(path, target_size=(150, 150))

  image_plot = plt.imshow(images)
  x = image.img_to_array(images)
  x = np.expand_dims(x, axis=0)
 
  images = np.vstack([x])
  predict_x = model.predict(images) 
  classes = np.argmax(predict_x,axis=1)

  if classes == 0:
    print("paper")
  elif classes == 1:
    print("rock")
  else:
    print("scissor")